# -*- coding: utf-8 -*-
"""System_Recomender_Movie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FWw4tkoPEdp1kRcPF-CYTfckQihHHz6n

# 1 Menyambungkan dengan penyimpanan Google Drive
"""

from google.colab import drive
drive.mount('/content/drive/')

"""Memberikan akses ke google drive

# 2 Mengimpor pustaka/modul python yang dibutuhkan
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud,STOPWORDS

from collections import Counter

import tensorflow as tf
from tensorflow import keras
from keras import layers

"""Mengimport library yang dibutuhkan untuk analisis

# 3 Data Understanding

### 3.1 Menyiapkan path dataset pada penyimpanan drive serta menampilkan overview dataset Movie menggunakan library pandas
"""

movies_meta_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MachineLearningTerapan/Machine-Learning-Terapan-2/movies.csv')

movies_meta_data

"""Mengimport file yang akan dianalisis lebih lanjut. Terdapat 9.742 baris dengan 3 kolom

### 3.2 Menampilkan keterangan jumlah/panjang data unique daftar film dan data pengguna/user
"""

print('Banyak Data movies ID: ', len(movies_meta_data.movieId.unique()))

"""Menampilkan jumlah data yang ada dengan 9742 movie

### 3.3 Menampilkan keterangan kolom dataset & cek kondisi data
"""

movies_meta_data.info()
print('missing values on dataset movie : \n', movies_meta_data.isnull().sum())

print('\nJumlah duplikat pada dataset movie:', movies_meta_data.duplicated().sum())

"""Memuat informasi dataframe movies_meta_data dan melihat missing value dan duplicate, seperti yang ditampilkan tidak ada missing value maupun duplicate pada semua data.

### 3.4 Menampilkan Daftar Genre pada dataset
"""

print('Jenis-jenis Genre pada dataset: ', movies_meta_data.genres.unique())

"""Menampilkan selutuh genre movie pada data

### 3.5 Menghitung besar/panjang data genre secara unique
"""

print('Jumlah data genre: ', len(movies_meta_data.genres.unique()))

"""Menghitung jumlah data genre data pada file movie.csv secara uniqe. Hasil menunjukkan bahwa terdapat 951 data yang uniqe

### 3.6 Memuat deskripsi setiap kolom dataframe untuk perhitungan count, rata-rata, minimal value dan maximal value, dll
"""

movies_meta_data.describe()

"""Memuat deskripsi setiap kolom dataframe"""

movies_meta_data.isnull().sum()

"""Menghitung jumlah data kosong pada setiap kolom

### 3.7 Memuat dataset ke dalam variable baru
"""

# Memuat dataset ke dalam variable baru
movie = movies_meta_data.movieId.unique()

# Mengurutkan data dan menghapus data yang sama
movie = np.sort(np.unique(movie))

print('Jumlah seluruh data movie berdasarkan movieId: ', len(movie))

"""Memuat dataset ke dalam variable baru dan Mengurutkan data dan menghapus data yang sama"""

movie_info = pd.concat([movies_meta_data])

movie_info

"""### 3.8 Menampilkan jumlah kata paling banyak yg muncul dalam kolom genre"""

word_could_dict = Counter(movies_meta_data['genres'].tolist())
wordcloud = WordCloud(width = 2000, height = 1000).generate_from_frequencies(word_could_dict)

plt.figure(figsize=(15,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

"""Menampilkan kata dengan frekuensi terbanyak pada kolom genre. Data menunjukkan kata "Drama" dan "Comedy" memiliki jumlah kata paling banyak

# 4 Data Preparation

### 4.1 Memilih kolom berdasarkan data yang dibutuhkan untuk melakukan content based learning berdasarkan genre yaitu judul dan genre
"""

judul_movie = movies_meta_data['title'].tolist()
genre_movie = movies_meta_data['genres'].tolist()

print(len(judul_movie))
print(len(genre_movie))

"""Memilih kolom berdasarkan data, terlihat masing-masing menampilkan 9742 data

### 4.2 Membuat data menjadi dalam bentuk dataframe sehingga mudah untuk dipersiapkan
"""

data = pd.DataFrame({
    'judul': judul_movie,
    'genre': genre_movie
})

data

data.info()

"""Melihat informasi kolom pada data, terlihat data type yaitu object tanpa missing value.

### 4.3 Memuat banyak data dari setiap unique value berdasarkan genre
"""

value_genre = pd.DataFrame(data['genre'].value_counts().reset_index().values, columns = ['genre', 'count'])
print(len(value_genre))
pd.options.display.max_colwidth = 500
value_genre

"""Data menunjukkan 951 data uniqe dengan dua kolom"""

data = data[data.genre != '-']

"""Membuat tanda '-' pada variabel data dihapus

Melihat kembali Jenis-Jenis Genre yang terdapat pada data
"""

data.genre.unique()

"""Melakukan drop pada judul film yg double, dan berhasil menghapus beberapa judul"""

data = data.drop_duplicates('judul')
len(data)

"""Melaukan drop pada judul yang duplikat dan mendapatkan 9737 data setelah dihapus

### 4.4 Melakukan indeks ulang pada data agar penomoran dilakukan berurutan
"""

data.reset_index()
data

"""### 4.5 Memasukkan nilai data masing-masing kolom ke dalam variabel baru"""

judul = data['judul'].tolist()
genre = data['genre'].tolist()

print(len(judul))
print(len(genre))

data = pd.DataFrame({
    'judul': judul,
    'genre': genre
})
data

"""Mengecek ulang data yg dimasukkan ke dalam variable baru

## 4.6 Proses Data

### 4.6.1 Membangun sistem rekomendasi berdasarkan genre yang ada pada setiap movies
"""

tfidf = TfidfVectorizer()
tfidf.fit(genre)
tfidf.get_feature_names_out()

"""### 4.6.2 Melakukan Proses fit dan melihat jumlah ukuran matrix"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfidf.fit_transform(genre)

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""### 4.6.3 Mengubah vektor ke dalam bentuk matrix"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""### 4.6.4 Melihat Daftar jumlah film berdasarkan genre dan melihat korelasi nya yg diperlihatkan dalam bentuk matrix"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(), # Corrected from tf.get_feature_names_out()
    index=data.judul
).sample(22, axis=1).sample(10, axis=0)

"""Data menunjukkan terdapat 10 baris dengan 22 kolom

# 5 Modeling

### 5.1 Melatih Model dengan cosine similarity
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""### 5.2 Menampilkan Matriks Kesamaan"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['judul'], columns=genre)
print('Shape:', cosine_sim_df.shape)


cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""## 5.3 Menampilkan hasil rekomendasi modelling"""

def movie_recommendations(judul, cosine_sim = cosine_sim,items=data[['judul','genre']]):
    # Mengambil indeks dari judul film yang telah didefinisikan sebelumnnya
    idx = indices[judul]

    # Mengambil skor kemiripan dengan semua judul film
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Mengurutkan film berdasarkan skor kemiripan
    sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)

    # Mengambil 20 skor kemiripan dari 1-20 karena urutan 0 memberikan indeks yang sama dengan judul film yang diinput
    sim_scores = sim_scores[1:20]

    # Mengambil judul film dari skor kemiripan
    movie_indices = [i[0] for i in sim_scores]

    # Mengembalikan 20 rekomendasi judul film dari kemiripan skor yang telah diurutkan dan menampilkan genre dari 20 rekomendasi film tersebut
    return pd.DataFrame(data['judul'][movie_indices]).merge(items)

recomendation = pd.DataFrame(movie_recommendations('Letter to Three Wives, A (1949)'))
recomendation

"""Berdasarkan modelling yang telah dibuat maka ditampilkan rekomendasi dari film berjudul Letter to Three Wives, A (1949) seperti di atas.

# 6 Evaluasi Model

### 6.1 Mengindikasi dan memperlihatkan judul film berdasarkan urutan dari data
"""

indices = pd.Series(index = data['judul'], data = data.index).drop_duplicates()
indices.head()

"""### 6.2 Membuat fungsi untuk memanggil 20 rekomendasi film berdasarkan judul yang di input"""

def movie_recommendations(judul, cosine_sim = cosine_sim,items=data[['judul','genre']]):
    # Mengambil indeks dari judul film yang telah didefinisikan sebelumnnya
    idx = indices[judul]

    # Mengambil skor kemiripan dengan semua judul film
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Mengurutkan film berdasarkan skor kemiripan
    sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)

    # Mengambil 20 skor kemiripan dari 1-20 karena urutan 0 memberikan indeks yang sama dengan judul film yang diinput
    sim_scores = sim_scores[1:20]

    # Mengambil judul film dari skor kemiripan
    movie_indices = [i[0] for i in sim_scores]

    # Mengembalikan 20 rekomendasi judul film dari kemiripan skor yang telah diurutkan dan menampilkan genre dari 20 rekomendasi film tersebut
    return pd.DataFrame(data['judul'][movie_indices]).merge(items)

data[data.judul.eq('Lost and Delirious (2001)')]

"""## 6.3 Menampilkan 19 rekomendasi film dari judul yang telah di input menggunakan fungsi movie_recomendations"""

recomendation = pd.DataFrame(movie_recommendations('Lost and Delirious (2001)'))
recomendation

"""## 6.4 Menghitung banyaknya data genre pada hasil rekomendasi"""

value = pd.DataFrame(recomendation['genre'].value_counts().reset_index().values, columns = ['genre', 'count'])
value.head()

"""Menghitung banyaknya data genre pada hasil rekomendasi yang dilaukan, data menampilkan terdapat 19 genre

## 6.5 Melakukan perhitungan dengan menggunakan metrik
"""

TP = 19 #jumlah prediksi benar untuk genre yang mirip atau serupa
FP = 0 #jumlah prediksi salah untuk genre yang mirip atau serupa

Precision = TP/(TP+FP)
print("{0:.0%}".format(Precision))

def precision_at_k(recommended_items, relevant_items, k):
    if not relevant_items:
        return 0.0
    recommended_at_k = recommended_items[:k]
    num_relevant_and_recommended = len(set(recommended_at_k) & set(relevant_items))
    return num_relevant_and_recommended / k if k > 0 else 0.0

def recall_at_k(recommended_items, relevant_items, k):
    if not relevant_items:
        return 0.0
    recommended_at_k = recommended_items[:k]
    num_relevant_and_recommended = len(set(recommended_at_k) & set(relevant_items))
    return num_relevant_and_recommended / len(relevant_items) if len(relevant_items) > 0 else 0.0

def average_precision(recommended_items, relevant_items):
    if not relevant_items:
        return 0.0

    sum_precisions = 0.0
    num_relevant_found = 0

    for i, item in enumerate(recommended_items):
        if item in relevant_items:
            num_relevant_found += 1
            precision_at_i = num_relevant_found / (i + 1)
            sum_precisions += precision_at_i

    return sum_precisions / len(relevant_items) if len(relevant_items) > 0 else 0.0

def mean_average_precision(list_of_recommended_items, list_of_relevant_items):
    aps = []
    for recommended, relevant in zip(list_of_recommended_items, list_of_relevant_items):
        aps.append(average_precision(recommended, relevant))
    return sum(aps) / len(aps) if len(aps) > 0 else 0.0

# Find the genre of 'Lost and Delirious (2001)'
target_genre = data[data['judul'] == 'Lost and Delirious (2001)']['genre'].iloc[0]

# Find all movies with the same genre
relevant_movies = data[data['genre'] == target_genre]['judul'].tolist()

# Get the recommended movie titles from your function's output
recommended_movies = recomendation['judul'].tolist()

# Set k for evaluation metrics
k = 10 # Evaluate the top 10 recommendations

# Calculate Precision@K
precision_k = precision_at_k(recommended_movies, relevant_movies, k)
print(f"Precision@{k}: {precision_k:.4f}")

# Calculate Recall@K
recall_k = recall_at_k(recommended_movies, relevant_movies, k)
print(f"Recall@{k}: {recall_k:.4f}")

# Calculate Average Precision for this single recommendation list
ap = average_precision(recommended_movies, relevant_movies)
print(f"Average Precision: {ap:.4f}")

# For Mean Average Precision (MAP), you would typically evaluate across multiple recommendation lists
# for different users or different query items.
# Let's simulate multiple recommendations for a few different movies
movie_titles_to_evaluate = ['Lost and Delirious (2001)', 'Toy Story (1995)', 'Heat (1995)']

all_recommended_lists = []
all_relevant_lists = []

for title in movie_titles_to_evaluate:
    # Get recommendations
    recs = movie_recommendations(title)['judul'].tolist()
    all_recommended_lists.append(recs)

    # Define relevant items (movies with the same genre)
    relevant_genre = data[data['judul'] == title]['genre'].iloc[0]
    relevant_movies_for_title = data[data['genre'] == relevant_genre]['judul'].tolist()
    all_relevant_lists.append(relevant_movies_for_title)

# Calculate MAP
map_score = mean_average_precision(all_recommended_lists, all_relevant_lists)
print(f"Mean Average Precision (MAP): {map_score:.4f}")